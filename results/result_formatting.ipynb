{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:42:04.939420500Z",
     "start_time": "2023-11-16T01:42:04.938420900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbabf28383d9352d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:42:05.141456700Z",
     "start_time": "2023-11-16T01:42:05.107460100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('result_subjective_metric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11317b511d4218c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:42:05.701216100Z",
     "start_time": "2023-11-16T01:42:05.671221Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.loc[results_df['Model'].str.contains('base'), 'model_order']=0\n",
    "results_df.loc[results_df['Model'].str.contains('7B'), 'model_order']=1\n",
    "results_df.loc[results_df['Model'].str.contains('13B'), 'model_order']=2\n",
    "results_df.loc[results_df['Model'].str.contains('gpt'), 'model_order']=3\n",
    "\n",
    "results_df.sort_values('model_order', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a401e35d58fb99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:42:06.465480900Z",
     "start_time": "2023-11-16T01:42:06.436968500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df['Model'] = results_df['Model'].replace({\n",
    "\"base-random\":\"Baseline random\",\n",
    "\"base-silent\":\"Baseline silent\",\n",
    "\"Falcon_7B_8-bit\":\"Falcon\",\n",
    "\"LLaMA2_7B_8-bit\":\"LLAMA2\",\n",
    "\"LLaMA2-Chat_7B_8-bit\":\"LLAMA2 Chat\",\n",
    "\"Mistral_7B_8-bit\":\"Mistral  7B\",\n",
    "\"Mistral-Instruct_7B_8-bit\":\"Mistral Instruct 7B\",\n",
    "\"Vicuna_7B_8-bit\":\"Vicuna 7B\",\n",
    "\"Zephyr_7B_8-bit\":\"Zephyr 7B\",\n",
    "\"WizardLM_7B_8-bit\":\"WizardLM 7B\",\n",
    "\"LLaMA2_13B_8-bit\":\"LLaMA2 13B\",\n",
    "\"LLaMA2-Chat_13B_8-bit\":\"LLaMA2 Chat 13B\",\n",
    "\"Vicuna_13B_8-bit\":\"Vicuna 13B\",\n",
    "\"WizardLM_13B_8-bit\":\"WizardLM 13B\",\n",
    "\"gpt-3.5\":\"GPT 3.5 175B\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fbcd87fb17d884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:42:07.554020200Z",
     "start_time": "2023-11-16T01:42:07.528804800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "    \\centering\n",
      "    \\resizebox{\\columnwidth}{!}{\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model & F1 Level 0 & F1 Level 1 & F1 Level 2 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.397 & 0.130 & 0.022 \\\\\n",
      "LLAMA2 Chat & 0.572 & 0.114 & 0.068 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.622 & 0.291 & 0.069 \\\\\n",
      "LLAMA2 & 0.492 & 0.148 & 0.038 \\\\\n",
      "Mistral Instruct 7B & 0.536 & 0.144 & 0.069 \\\\\n",
      "Mistral  7B & 0.450 & 0.127 & 0.044 \\\\\n",
      "Vicuna 7B & 0.494 & 0.134 & 0.051 \\\\\n",
      "WizardLM 7B & 0.490 & 0.087 & 0.036 \\\\\n",
      "Zephyr 7B & 0.524 & 0.192 & 0.098 \\\\\n",
      "LLaMA2 Chat 13B & 0.549 & 0.160 & 0.096 \\\\\n",
      "LLaMA2 13B & 0.458 & 0.129 & 0.039 \\\\\n",
      "Vicuna 13B & 0.557 & 0.173 & 0.100 \\\\\n",
      "WizardLM 13B & 0.520 & 0.177 & 0.093 \\\\\n",
      "GPT 3.5 175B & 0.627 & 0.201 & 0.138 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "    \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"\\\\begin{table}[h!]\n",
    "    \\\\centering\n",
    "    \\\\resizebox{\\\\columnwidth}{!}{\"\"\" +\n",
    "        results_df[['Model', 'F1 Level 0','F1 Level 1','F1 Level 2']].to_latex(index=False, float_format=\"{:.3f}\".format) +\n",
    "   \"\"\"}\n",
    "    \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f29a7431d4fb12f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:42:09.293775900Z",
     "start_time": "2023-11-16T01:42:09.268760500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Model', 'Precision Level 0', 'Recall Level 0', 'F1 Level 0',\n",
       "       'Precision Level 1', 'Recall Level 1', 'F1 Level 1',\n",
       "       'Precision Level 2', 'Recall Level 2', 'F1 Level 2',\n",
       "       'Label Precision Level 0', 'Label Recall Level 0', 'Label F1 Level 0',\n",
       "       'Label Precision Level 1', 'Label Recall Level 1', 'Label F1 Level 1',\n",
       "       'Label Precision Level 2', 'Label Recall Level 2', 'Label F1 Level 2',\n",
       "       'model_order'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86238d297e95f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:42:10.083153600Z",
     "start_time": "2023-11-16T01:42:10.069157800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "    \\centering\n",
      "    \\resizebox{\\columnwidth}{!}{\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model & Label F1 Level 0 & Label F1 Level 1 & Label F1 Level 2 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.600 & 0.368 & 0.095 \\\\\n",
      "LLAMA2 Chat & 0.685 & 0.346 & 0.180 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.933 & 0.587 & 0.157 \\\\\n",
      "LLAMA2 & 0.640 & 0.406 & 0.113 \\\\\n",
      "Mistral Instruct 7B & 0.655 & 0.485 & 0.264 \\\\\n",
      "Mistral  7B & 0.615 & 0.400 & 0.128 \\\\\n",
      "Vicuna 7B & 0.610 & 0.440 & 0.207 \\\\\n",
      "WizardLM 7B & 0.625 & 0.426 & 0.256 \\\\\n",
      "Zephyr 7B & 0.675 & 0.502 & 0.270 \\\\\n",
      "LLaMA2 Chat 13B & 0.670 & 0.424 & 0.234 \\\\\n",
      "LLaMA2 13B & 0.660 & 0.415 & 0.123 \\\\\n",
      "Vicuna 13B & 0.710 & 0.549 & 0.332 \\\\\n",
      "WizardLM 13B & 0.710 & 0.460 & 0.244 \\\\\n",
      "GPT 3.5 175B & 0.720 & 0.616 & 0.483 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "    \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"\\\\begin{table}[h!]\n",
    "    \\\\centering\n",
    "    \\\\resizebox{\\\\columnwidth}{!}{\"\"\" +\n",
    "        results_df[['Model', 'Label F1 Level 0','Label F1 Level 1','Label F1 Level 2']].to_latex(index=False, float_format=\"{:.3f}\".format) +\n",
    "   \"\"\"}\n",
    "    \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71f79860c904d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:42:10.786620600Z",
     "start_time": "2023-11-16T01:42:10.771620900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "    \\centering\n",
      "    \\resizebox{\\columnwidth}{!}{\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "Model & Precision Level 0 & Recall Level 0 & F1 Level 0 & Precision Level 1 & Recall Level 1 & F1 Level 1 & Precision Level 2 & Recall Level 2 & F1 Level 2 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.427 & 0.655 & 0.397 & 0.134 & 0.164 & 0.130 & 0.016 & 0.078 & 0.022 \\\\\n",
      "LLAMA2 Chat & 0.506 & 0.837 & 0.572 & 0.134 & 0.136 & 0.114 & 0.070 & 0.095 & 0.068 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.597 & 0.835 & 0.622 & 0.267 & 0.427 & 0.291 & 0.048 & 0.233 & 0.069 \\\\\n",
      "LLAMA2 & 0.456 & 0.758 & 0.492 & 0.158 & 0.185 & 0.148 & 0.038 & 0.073 & 0.038 \\\\\n",
      "Mistral Instruct 7B & 0.570 & 0.651 & 0.536 & 0.176 & 0.152 & 0.144 & 0.086 & 0.076 & 0.069 \\\\\n",
      "Mistral  7B & 0.444 & 0.691 & 0.450 & 0.136 & 0.159 & 0.127 & 0.046 & 0.072 & 0.044 \\\\\n",
      "Vicuna 7B & 0.529 & 0.628 & 0.494 & 0.161 & 0.146 & 0.134 & 0.062 & 0.067 & 0.051 \\\\\n",
      "WizardLM 7B & 0.565 & 0.567 & 0.490 & 0.121 & 0.093 & 0.087 & 0.056 & 0.041 & 0.036 \\\\\n",
      "Zephyr 7B & 0.489 & 0.765 & 0.524 & 0.207 & 0.230 & 0.192 & 0.090 & 0.145 & 0.098 \\\\\n",
      "LLaMA2 Chat 13B & 0.493 & 0.793 & 0.549 & 0.173 & 0.183 & 0.160 & 0.101 & 0.122 & 0.096 \\\\\n",
      "LLaMA2 13B & 0.433 & 0.739 & 0.458 & 0.140 & 0.151 & 0.129 & 0.037 & 0.068 & 0.039 \\\\\n",
      "Vicuna 13B & 0.591 & 0.670 & 0.557 & 0.200 & 0.191 & 0.173 & 0.115 & 0.118 & 0.100 \\\\\n",
      "WizardLM 13B & 0.523 & 0.756 & 0.520 & 0.193 & 0.205 & 0.177 & 0.088 & 0.134 & 0.093 \\\\\n",
      "GPT 3.5 175B & 0.701 & 0.669 & 0.627 & 0.233 & 0.203 & 0.201 & 0.162 & 0.138 & 0.138 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "    \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"\\\\begin{table}[h!]\n",
    "    \\\\centering\n",
    "    \\\\resizebox{\\\\columnwidth}{!}{\"\"\" +\n",
    "        results_df[['Model', 'Precision Level 0', 'Recall Level 0', 'F1 Level 0',\n",
    "       'Precision Level 1', 'Recall Level 1', 'F1 Level 1',\n",
    "       'Precision Level 2', 'Recall Level 2', 'F1 Level 2']].to_latex(index=False, float_format=\"{:.3f}\".format) +\n",
    "   \"\"\"}\n",
    "    \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68b7bad5d6d5ff9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:46:34.053755200Z",
     "start_time": "2023-11-16T01:46:34.032301600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "    \\centering\n",
      "    \\resizebox{\\columnwidth}{!}{\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model & Precision Level 0 & Recall Level 0 & F1 Level 0 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.427 & 0.655 & 0.397 \\\\\n",
      "LLAMA2 Chat & 0.506 & 0.837 & 0.572 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.597 & 0.835 & 0.622 \\\\\n",
      "LLAMA2 & 0.456 & 0.758 & 0.492 \\\\\n",
      "Mistral Instruct 7B & 0.570 & 0.651 & 0.536 \\\\\n",
      "Mistral  7B & 0.444 & 0.691 & 0.450 \\\\\n",
      "Vicuna 7B & 0.529 & 0.628 & 0.494 \\\\\n",
      "WizardLM 7B & 0.565 & 0.567 & 0.490 \\\\\n",
      "Zephyr 7B & 0.489 & 0.765 & 0.524 \\\\\n",
      "LLaMA2 Chat 13B & 0.493 & 0.793 & 0.549 \\\\\n",
      "LLaMA2 13B & 0.433 & 0.739 & 0.458 \\\\\n",
      "Vicuna 13B & 0.591 & 0.670 & 0.557 \\\\\n",
      "WizardLM 13B & 0.523 & 0.756 & 0.520 \\\\\n",
      "GPT 3.5 175B & 0.701 & 0.669 & 0.627 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "    \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"\\\\begin{table}[h!]\n",
    "    \\\\centering\n",
    "    \\\\resizebox{\\\\columnwidth}{!}{\n",
    "\"\"\" +\n",
    "        results_df[['Model', 'Precision Level 0', 'Recall Level 0', 'F1 Level 0']].to_latex(index=False, float_format=\"{:.3f}\".format) +\n",
    "   \"\"\"}\n",
    "    \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10081fff0db53750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:46:50.053658300Z",
     "start_time": "2023-11-16T01:46:50.038272Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\resizebox{\\columnwidth}{!}{\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model & Precision Level 1 & Recall Level 1 & F1 Level 1 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.134 & 0.164 & 0.130 \\\\\n",
      "LLAMA2 Chat & 0.134 & 0.136 & 0.114 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.267 & 0.427 & 0.291 \\\\\n",
      "LLAMA2 & 0.158 & 0.185 & 0.148 \\\\\n",
      "Mistral Instruct 7B & 0.176 & 0.152 & 0.144 \\\\\n",
      "Mistral  7B & 0.136 & 0.159 & 0.127 \\\\\n",
      "Vicuna 7B & 0.161 & 0.146 & 0.134 \\\\\n",
      "WizardLM 7B & 0.121 & 0.093 & 0.087 \\\\\n",
      "Zephyr 7B & 0.207 & 0.230 & 0.192 \\\\\n",
      "LLaMA2 Chat 13B & 0.173 & 0.183 & 0.160 \\\\\n",
      "LLaMA2 13B & 0.140 & 0.151 & 0.129 \\\\\n",
      "Vicuna 13B & 0.200 & 0.191 & 0.173 \\\\\n",
      "WizardLM 13B & 0.193 & 0.205 & 0.177 \\\\\n",
      "GPT 3.5 175B & 0.233 & 0.203 & 0.201 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      " \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"\\\\begin{table}[h!]\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\columnwidth}{!}{\n",
    "\"\"\" +\n",
    "results_df[['Model', 'Precision Level 1', 'Recall Level 1', 'F1 Level 1']].to_latex(index=False,\n",
    "                                                                                    float_format=\"{:.3f}\".format) +\n",
    "\"\"\"}\n",
    " \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0953f2a041342e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:47:14.776274300Z",
     "start_time": "2023-11-16T01:47:14.737742500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\resizebox{\\columnwidth}{!}{\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model & Precision Level 2 & Recall Level 2 & F1 Level 2 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.016 & 0.078 & 0.022 \\\\\n",
      "LLAMA2 Chat & 0.070 & 0.095 & 0.068 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.048 & 0.233 & 0.069 \\\\\n",
      "LLAMA2 & 0.038 & 0.073 & 0.038 \\\\\n",
      "Mistral Instruct 7B & 0.086 & 0.076 & 0.069 \\\\\n",
      "Mistral  7B & 0.046 & 0.072 & 0.044 \\\\\n",
      "Vicuna 7B & 0.062 & 0.067 & 0.051 \\\\\n",
      "WizardLM 7B & 0.056 & 0.041 & 0.036 \\\\\n",
      "Zephyr 7B & 0.090 & 0.145 & 0.098 \\\\\n",
      "LLaMA2 Chat 13B & 0.101 & 0.122 & 0.096 \\\\\n",
      "LLaMA2 13B & 0.037 & 0.068 & 0.039 \\\\\n",
      "Vicuna 13B & 0.115 & 0.118 & 0.100 \\\\\n",
      "WizardLM 13B & 0.088 & 0.134 & 0.093 \\\\\n",
      "GPT 3.5 175B & 0.162 & 0.138 & 0.138 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      " \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"\\\\begin{table}[h!]\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\columnwidth}{!}{\n",
    "\"\"\" +\n",
    "results_df[['Model', 'Precision Level 2', 'Recall Level 2', 'F1 Level 2']].to_latex(index=False,\n",
    "                                                                                    float_format=\"{:.3f}\".format) +\n",
    "\"\"\"}\n",
    " \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "101c135a91d9407d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:50:29.654354300Z",
     "start_time": "2023-11-16T01:50:29.603823700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\resizebox{\\columnwidth}{!}{\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model & Label Precision Level 0 & Label Recall Level 0 & Label F1 Level 0 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.600 & 0.600 & 0.600 \\\\\n",
      "LLAMA2 Chat & 0.685 & 0.685 & 0.685 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.933 & 0.933 & 0.933 \\\\\n",
      "LLAMA2 & 0.640 & 0.640 & 0.640 \\\\\n",
      "Mistral Instruct 7B & 0.655 & 0.655 & 0.655 \\\\\n",
      "Mistral  7B & 0.615 & 0.615 & 0.615 \\\\\n",
      "Vicuna 7B & 0.610 & 0.610 & 0.610 \\\\\n",
      "WizardLM 7B & 0.625 & 0.625 & 0.625 \\\\\n",
      "Zephyr 7B & 0.675 & 0.675 & 0.675 \\\\\n",
      "LLaMA2 Chat 13B & 0.670 & 0.670 & 0.670 \\\\\n",
      "LLaMA2 13B & 0.660 & 0.660 & 0.660 \\\\\n",
      "Vicuna 13B & 0.710 & 0.710 & 0.710 \\\\\n",
      "WizardLM 13B & 0.710 & 0.710 & 0.710 \\\\\n",
      "GPT 3.5 175B & 0.720 & 0.720 & 0.720 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      " \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"\\\\begin{table}[h!]\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\columnwidth}{!}{\n",
    "\"\"\" +\n",
    "results_df[['Model', 'Label Precision Level 0', 'Label Recall Level 0', 'Label F1 Level 0']].to_latex(index=False,\n",
    "                                                                                    float_format=\"{:.3f}\".format) +\n",
    "\"\"\"}\n",
    " \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad763ce83626d803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:50:42.129709600Z",
     "start_time": "2023-11-16T01:50:42.098703600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\resizebox{\\columnwidth}{!}{\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model & Label Precision Level 1 & Label Recall Level 1 & Label F1 Level 1 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.305 & 0.542 & 0.368 \\\\\n",
      "LLAMA2 Chat & 0.314 & 0.426 & 0.346 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.471 & 0.887 & 0.587 \\\\\n",
      "LLAMA2 & 0.343 & 0.559 & 0.406 \\\\\n",
      "Mistral Instruct 7B & 0.474 & 0.537 & 0.485 \\\\\n",
      "Mistral  7B & 0.349 & 0.531 & 0.400 \\\\\n",
      "Vicuna 7B & 0.431 & 0.487 & 0.440 \\\\\n",
      "WizardLM 7B & 0.416 & 0.463 & 0.426 \\\\\n",
      "Zephyr 7B & 0.465 & 0.593 & 0.502 \\\\\n",
      "LLaMA2 Chat 13B & 0.402 & 0.497 & 0.424 \\\\\n",
      "LLaMA2 13B & 0.357 & 0.556 & 0.415 \\\\\n",
      "Vicuna 13B & 0.537 & 0.598 & 0.549 \\\\\n",
      "WizardLM 13B & 0.417 & 0.573 & 0.460 \\\\\n",
      "GPT 3.5 175B & 0.628 & 0.623 & 0.616 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      " \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"\\\\begin{table}[h!]\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\columnwidth}{!}{\n",
    "\"\"\" +\n",
    "results_df[['Model', 'Label Precision Level 1', 'Label Recall Level 1', 'Label F1 Level 1']].to_latex(index=False,\n",
    "                                                                                    float_format=\"{:.3f}\".format) +\n",
    "\"\"\"}\n",
    " \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "badea18c68ede013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T01:50:54.332173100Z",
     "start_time": "2023-11-16T01:50:54.309161900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\resizebox{\\columnwidth}{!}{\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model & Label Precision Level 2 & Label Recall Level 2 & Label F1 Level 2 \\\\\n",
      "\\midrule\n",
      "Falcon & 0.067 & 0.346 & 0.095 \\\\\n",
      "LLAMA2 Chat & 0.144 & 0.292 & 0.180 \\\\\n",
      "LLaMA2-Instruct_7B_8-bit & 0.096 & 0.631 & 0.157 \\\\\n",
      "LLAMA2 & 0.082 & 0.315 & 0.113 \\\\\n",
      "Mistral Instruct 7B & 0.257 & 0.316 & 0.264 \\\\\n",
      "Mistral  7B & 0.098 & 0.314 & 0.128 \\\\\n",
      "Vicuna 7B & 0.188 & 0.264 & 0.207 \\\\\n",
      "WizardLM 7B & 0.255 & 0.285 & 0.256 \\\\\n",
      "Zephyr 7B & 0.227 & 0.427 & 0.270 \\\\\n",
      "LLaMA2 Chat 13B & 0.202 & 0.342 & 0.234 \\\\\n",
      "LLaMA2 13B & 0.091 & 0.304 & 0.123 \\\\\n",
      "Vicuna 13B & 0.314 & 0.404 & 0.332 \\\\\n",
      "WizardLM 13B & 0.209 & 0.427 & 0.244 \\\\\n",
      "GPT 3.5 175B & 0.491 & 0.495 & 0.483 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      " \\caption{Performance results of different models across different granularity levels in a zero-shot setting \\label{tab:result}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"\\\\begin{table}[h!]\n",
    "\\\\centering\n",
    "\\\\resizebox{\\\\columnwidth}{!}{\n",
    "\"\"\" +\n",
    "results_df[['Model', 'Label Precision Level 2', 'Label Recall Level 2', 'Label F1 Level 2']].to_latex(index=False,\n",
    "                                                                                    float_format=\"{:.3f}\".format) +\n",
    "\"\"\"}\n",
    " \\\\caption{Performance results of different models across different granularity levels in a zero-shot setting \\\\label{tab:result}}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
